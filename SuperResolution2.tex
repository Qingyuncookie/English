\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{cvpr}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{subfig}

\graphicspath{{/home/li/图片/}}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{fontspec}

\usepackage[pagebackref=true,breaklinks=true,letterpaper=true,colorlinks,bookmarks=false]{hyperref}

\cvprfinalcopy % *** Uncomment this line for the final submission

\def\cvprPaperID{****} % *** Enter the CVPR Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

\ifcvprfinal\pagestyle{empty}\fi
\setcounter{page}{1}

\begin{document}

\author{Qingyun Li\\\\
June 11, 2018}        
\title{Super Resolution}

\maketitle

\begin{abstract}
 \par
  Image resolution is an important indicator of image detail rendering capability. It describes the number of pixels contained in an image. However, due to the limitations of the hardware conditions of the image acquisition system, we can't acquire the high-resolution image. Image super resolution refers to the recovery of high-resolution image from low-resolution image or image sequence. There are three methods in general, interpolation, reconstrution and learning.  High resolution means that the pixels in the image are high in density and can provide more detail, and these are very helpful. For example, the doctors can make a correct diagnosis according to the high resolution medical resolutions. And we can distinguish similar objects from the high-resolution satellite images. Therefore, the performance of pattern recognition will be greatly improved. So it is critical to research the high-resolution images. This paper will focus on the method based on learning.
\end{abstract}
\section{Artificial neural net}
 \par Artificial neural net models have been studied for many years in the hope of achiving human-like performance in the fields of speech and image recognition. These models are composed of many nonlinear computational elements operating in parallel and arranged in patterns reminiscent of biological neural nets. Computational elements or nodes are connected via weights that are typically adapted during use to improve performance. There has been a recent resurgence in the field of artificial nerual nets caused by new net topologies and algorithms, analog VLSI implementation techniques, and the belief that massive parallelism is essential for high performance speech and image recognitio~\cite{lippmann1987introduction}.
\subsection{Naural net and traditional classifiers}
\par Block diagrams of traditional and neural net classifiers are presented in Fig.~\ref{block} Both types of classifiers determine which of M classes is most representative of an unknown static input pattern containing N input elements. In a speech, recognizer the inputs might be the output envelope values from a filter bank spectral analyzer sampled at one time instant and the classes might represent different vowels. In an image classifier the inputs might be the gray scale level of each pixel for a picture and the classes might represent different objects.
\par The top of the figure is the traditional classifier and the bottom of the figure is an adaptive nerual net classifier. The troditional classifier contains two stages. The first computes matching scores for each class and the second selects the class with the maximum score. And multivariate gaussian distributions are often used leading to relatively simple algorithms for computing matching scores~\cite{elman1988learning}.
 \begin{figure}[htbp]
 \centering{}
\includegraphics[width=0.7\linewidth]{BlockDiagrams.png}\\
 \caption{Block diagrams}
\label{block}
\end{figure}
\par An adaptive neural net classifier is shown at the bottom of Fig.~\ref{block}. Here input values are fed in parallel to the first stage N input connections. Each connection carries an analog value which may take on two levels for binary inputs. The first stage computes matching scores and outputs these scores in parallel to the next stage over M analog output lines. Here the maximum of these values is selected and enhanced. The second stage has one output for each of the M classes.
 \bibliographystyle{ieee}
 \bibliography{single}
\end{document}
